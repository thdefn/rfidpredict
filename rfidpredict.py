# -*- coding: utf-8 -*-
"""조달청

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LURDxIx22R4CPJKChqmWTMqYRAlW_Pxn
"""

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches 
from matplotlib import rc
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
import seaborn as sns 
import tensorflow as tf

!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

# bigapart.csv / rfid.csv 파일 아래 링크에서 다운로드 해주세요
# https://drive.google.com/drive/folders/10CVI7zvqlhKdOXwsftWOKm8x-0G1JJtB?usp=sharing

#https://www.k-apt.go.kr/board/boardView.do?board_type=03&page_no=1&seq=20&board_secret=0&stype=all&keyword=&board_pwd=&board_pwd_fake#
#전국 아파트 동수 데이터 전처리
bigapart = pd.read_csv('bigapart.csv')
bigapart = bigapart.rename(columns=bigapart.iloc[0])
bigapart = bigapart.drop(bigapart.index[0])
bigapart = bigapart[['시도', '시군구', '동수']]
bigapart = bigapart.dropna()

cols = ['시도', '시군구']
bigapart['지역'] = bigapart[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

bigapart = bigapart[['지역', '동수']]
bigapart
bigapart = bigapart.astype({'동수':'int'})
loca = bigapart.drop_duplicates(['지역'])['지역']

apartres = bigapart.drop_duplicates(['지역'])

list = []
for i in loca:
  is_in = (bigapart['지역'] == i)
  tmp = bigapart[is_in]
  list.append(tmp['동수'].sum()) 
  #print(i)
  #print(tmp)

list
apartres['합계동수'] = list

apartres

# https://www.data.go.kr/data/15061767/fileData.do 데이터셋
# rfid 데이터와 전국 아파트 동수 데이터 맵핑
rfid = pd.read_csv('rfid.csv', encoding='cp949')
cols = ['광역지자체', '기초지자체']
rfid['지역'] = rfid[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)
rfid = pd.merge(rfid, apartres, on = '지역', how = 'inner')

data = rfid[['지역', 'RFID종량기 수','합계동수', '(추정) 세대수']]
data.columns = ['지역', '종량기수', '아파트수', '세대수'] 
data = data.astype({'아파트수':'int', '세대수':'int', '종량기수':'int'})
data

data['state'] = data.지역.str.split(' ').str[0]
data['city'] = data.지역.str.split(' ').str[1]
data['비율'] = data['종량기수']/data['세대수']
data.head()

data.describe()
# 과도하게 많은 값(이상치)이 있는지 확인
# 김포시 / 서귀포시 / 철원군 / 홍천군 / 함평군 데이터가 이상치로 보임 
out = data[data['비율'] >= data['비율'].quantile(0.9)].sort_values(by='비율', ascending=False)
out

# 과도하게 적은 값(이상치)이 있는지 확인
# 광주시 데이터가 이상치로 보임
out2 = data[data['비율'] <= data['비율'].quantile(0.1)].sort_values(by='비율', ascending=True)
out2

rfid_mean = data['비율'].mean()
rfid_mean

# 이상치 삭제 처리
data = data[data['비율'] != data['비율'].min()]
for i in range(5):
  data = data[data['비율'] != data['비율'].max()]
data.describe()

# 이상치 제거한 데이터 scatter plot으로 확인

plt.rc("font", family='NanumGothic')
plt.figure(figsize=(20,10))
plt.scatter(data['state'],data['비율'], )
plt.axhline(y=rfid_mean, color='black')
plt.show()

df_sort_index = data[data['지역'].str.contains('서울')].sort_values(by='비율', ascending=True)
df_sort_index

## 성북구와 동대문구의 종량기가 모자름

# 세대수와 아파트수를 기반으로 종량기수를 예측
traindata = data[['세대수', '아파트수']]
targetdata = data['종량기수']
X_train, X_test, y_train, y_test = train_test_split(traindata, targetdata, test_size=0.2, random_state=121)
X_train
print(type(X_train))

# 총 세개의 활성층을 거쳐 학습
# train 데이터가 두 개의 컬럼으로 이루어져 있으므로 첫번째 활성층의 input_dim을 2로 설정
# 회귀 예측 모델이기 때문에 마지막 활성함수를 linear 로 설정하고, output shape도 1로 설정함
model = tf.keras.models.Sequential([
     tf.keras.layers.Dense(128, input_dim=2, activation='relu'),
     tf.keras.layers.Dense(1, activation='linear')                       
])

print(model.summary())

# 경사하강을 보정할 러닝 레이트 최적화 알고리즘으로 Adam을 사용해 컴파일
# 손실함수로 평균오차제곱을 사용하였으며 평가지표로는 평균 절대 오차를 사용함
opt = tf.keras.optimizers.Adam(learning_rate=0.001)
model.compile(opt, loss='mean_squared_error', metrics=['mae'])

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_mae', patience=10, restore_best_weights=True)

model.fit(np.array(X_train), np.array(y_train), epochs=1500, verbose=0)

# 종량기 개수 실제값과 예측값의 차이가 평균 95
# 종량기 개수가 전부 다 적정값인 게 아니고 일부는 많고 - 일부만 적절 - 일부는 적으므로 mae가 95가 나온 것으로 생각됨 종량기 개수가 이천단위가 넘어가는 지역도 있으므로 mae의 값에 큰 영향을 끼쳤을 것
model.evaluate(np.array(X_test), np.array(y_test))

# 예측값 추가할 result 데이터 프레임 생성
res_data = data[data['지역'].str.contains('서울')][['지역', '종량기수', '아파트수', '세대수']]
pre_data = []
for i, rows in res_data.iterrows():
  pre_data.append([rows['세대수'], rows['아파트수']])

res_data

preres = model.predict(pre_data)

df_res = pd.DataFrame(preres, index = res_data['지역'], columns=['예측값'])

res = pd.merge(res_data[['지역', '종량기수']], df_res, on='지역')

res['예측대비종량기비율'] = round(res['종량기수']/res['예측값']*100, 2)
res

res.describe()

# 결과 데이터셋 중 백분위수 0.1 이하인 값 출력
# 성북구, 금천구, 동대문구의 종량기 보급 비율이 낮았다
out = res[res['예측대비종량기비율'] <= res['예측대비종량기비율'].quantile(0.1)].sort_values(by='예측대비종량기비율', ascending=True)
print(out)
rfid_line = res['예측대비종량기비율'].quantile(0.1)

# 예측값과 실제값에 대한 swarmplot 시각화
plt.rc('font', family='NanumBarunGothic')
plt.figure(figsize=(40, 10))
sns.swarmplot(x='지역', y='종량기수', data=res, color="black")
sns.swarmplot(x='지역', y='예측값', data=res, color="red")

var_x = mpatches.Patch(color='black', label='종량기수')
var_y = mpatches.Patch(color='red', label='예측값')

plt.legend(handles=[var_x, var_y], loc = 'upper right')
plt.show()

# 부족한 지역을 한 눈에 보기 위해 백분위수 0.1 라인을 그어 scatter chart 생성
plt.rc("font", family='NanumGothic')
plt.figure(figsize=(40,10))
plt.scatter(res['지역'],res['예측대비종량기비율'], )
plt.axhline(y=rfid_line, color='black')
plt.show()

성북구동대문구금천구=pd.read_csv("한국환경공단_지자체별 RFID음식물쓰레기 배출량_07_31_2020.csv")
성북구동대문구금천구_필터링=성북구동대문구금천구['기초지자체'].str.contains("성북구|동대문구|금천구")
성북구동대문구금천구_필터링=성북구동대문구금천구[성북구동대문구금천구_필터링]
성북구동대문구금천구_필터링

plt.rc('font',family='Malgun Gothic')
plt.rcParams["figure.figsize"]=[8,5]
sns.barplot(data=성북구동대문구금천구_필터링,x='배출연도',y='배출량(톤)', hue='기초지자체', ci=False)
plt.title("2019년도 월별 성북구, 동대문구, 금천구 음식물쓰레기 배출량")

df=pd.DataFrame({'지자체':['동대문구','성북구','금천구',
                        '동대문구','성북구','금천구'],
                '종량기 당 음식물쓰레기 배출량':[100,85,76,126,75,63],
                '시기':['현재','현재','현재','예측','예측','예측']})

# 음식물쓰레기량은 2018년도,2019년도의 차이로 예측
sns.barplot(data=df,x='지자체',y='종량기 당 음식물쓰레기 배출량', hue='시기', ci=False)
plt.title("[예측] RFID 종량기 1대당 평균 음식물쓰레기 배출량 변화")